>>>markdown
To learn some Malloy's basic i've chosen Northwind dataset and would like to answer all the questions from Curbal's '25 Days of DAX Fridays! Challenge â€“ Ed1: NorthWind Company' (https://curbal.com/25-days-of-dax-fridays-challenge-ed1-northwind-company).

This challenge is a great way to train DAX skills and i highly recommend it to anyone working with Power Bi. 

Now in this challenge all the answer are in form of single metric or string - i will not be returning tables here and i will not be able to show some of Malloy's concepts (e.g. queries with 'nest').
>>>markdown


I've decided to use csv files from this source:
https://github.com/graphql-compose/graphql-compose-examples/tree/master/examples/northwind/data/csv .
When using csv or parquet files DuckDb is used as underlying engine. 
There are also options to connect to BigQuery or Postgres.

Dataset consists of 11 tables (2 tables are missing from original schema: customer_customer_demo and customer_demographics).

This how original schema looks like: (from https://github.com/yugabyte/yugabyte-db/wiki/Northwind-Sample-Database)

![Alt text](schema.png)


THE MODEL

To start using Malloy i need to first create model. That includes defining data sources, specifying joins, creating dimensions and measures. Malloy is designed in a way to work swiftly with transactional data and from what i red there is no need to create dimensional model (e.g. star schema). This is a different approach than the one in Power Bi ecosystem, where the best practice is to create star schema, a design that guarantees good performance and simplified DAX code.

I can work on the model in two ways:
1. As i have database schema i can specify joins from start. To join sources their definition needs to exist so I would have to start from outermost tables in the schema and move to the center.  
2. First define base sources from tables together with measures and dimensions (we can think about dimensions as calculated columns in PBI world). This join-less model would allow me to calculate most of the interesting numbers from those tables. For cross-table metrics, i would create new sources by extending those base sources with joins.


There is also an option to define join in a source on the fly (so it would work only inside query) using 'run: source_name extend {}'.

In this project I will define all my sources + joins in the first cell:
>>>malloy

-- starting with OrderDetails branch. First defining Categories and Suppliers and then joining them inside Products:
source: Categories is duckdb.table('../northwind_test/parquet/categories.parquet')
    extend {
        primary_key: categoryID
    }

source: Suppliers is duckdb.table('../northwind_test/parquet/suppliers.parquet')
    extend {
        primary_key: supplierID
    }

source: Products is duckdb.table('../northwind_test/parquet/products.parquet') 
    extend {
        primary_key: productID

        join_one: Categories with categoryID
        join_one: Suppliers with supplierID

        measure: 
            product_count is count()
            total_price is unitPrice.sum()
            avg_price is round(unitPrice.avg(),2)
            all_avg_price is all(avg(unitPrice))
            all_max_price is all(max(unitPrice))
      
        
}

-- now product needs to be joined to OrderDetails - one product can be joined to many Orders:

source: OrderDetails is duckdb.table('../northwind_test/parquet/order_details.parquet')
    extend {

        join_one: Products on Products.productID = productID

         dimension: revenue is unitPrice * quantity -- added for question #7
    }

-- ok so i have one 'branch' of the model. Now i need to do the same with second Orders branch. Starting with edge tables:

source: Customers is duckdb.table('../northwind_test/parquet/customers.parquet')
    extend {
        primary_key: customerID
    }

source: Shippers is duckdb.table('../northwind_test/parquet/shippers.parquet') 
    extend {
        primary_key: shipperID
    }

-- Customers and Shippers will be joined to Orders later.


source: Regions is duckdb.table('../northwind_test/parquet/regions.parquet') 
    extend {
        primary_key: regionID
    }

--now i will join Regions to Territories

source: Territories is duckdb.table('../northwind_test/parquet/territories.parquet') 
    extend {
        primary_key: territoryID

        join_one: Regions with regionID
    }

-- next Territories to EmployeeTerritories (this is a bridge table) then latter to Emplyees and in the end to Orders:

source: EmployeeTerritories is duckdb.table('../northwind_test/parquet/employee_territories.parquet')
    extend {
        
        join_one: Territories on Territories.territoryID = territoryID
        
    }

source: Employees  is duckdb.table('../northwind_test/parquet/employees.parquet')
    extend {
        primary_key: employeeID

        join_many: EmployeeTerritories on EmployeeTerritories.employeeID = employeeID
    }

--lastly Orders where i join above branch and also OrderDetails branch together 
source: Orders is duckdb.table('../northwind_test/parquet/orders.parquet')
    extend {
        primary_key: orderID

        join_one: Customers with customerID
        join_one: Shippers on Shippers.shipperID = shipVia
        join_one: Employees with employeeID
        join_many: OrderDetails on OrderDetails.orderID = orderID

        dimension: 
            order_date is orderDate::date
            order_year is year(orderDate)
        measure: 
            order_count is count()
            
    }
>>>markdown

Question 1: How many current products cost less then 20$?
>>>malloy

run: Products -> {
    aggregate: product_count --measure
    where: discontinued = 0 and
    unitPrice < 20
}
>>>markdown

Question 2: Which product is the most expensive? Success at third try. Currently correlated subqueries are not available in Malloy so i added a column with ALL (like calculated column in PBI) and then filtered by the value in this column:
>>>malloy

-- First attempt, but returned both name and price. As malloys is translated to SQL, 'ordery_by' is still computed after 'project'
-- so we need to have unitPrice included in 'project'
run: Products -> {
    order_by: unitPrice desc
    project: productName, unitPrice
    limit: 1
}

-- same result as above but in different way, this time instead of run i am defining a named query:
query: top_customer is Products -> {
  group_by: productName
  aggregate: total_price --measure
  limit: 1
}

--Third version using pipeline, this time only name is returned. Bingo!
run:  Products -> {
   group_by: productName, unitPrice    
   aggregate: all_max_price  --measure
    
} -> {
    project: productName
    where: unitPrice = all_max_price  
}


>>>markdown

Question 3: What is the average unit price for our products?
>>>malloy


run: Products -> {
    aggregate: avg_price  --measure
}
>>>markdown

Question 4: How many products are above the average unit price? 

Here using pipeline again + measure with 'all'
>>>malloy

-- First version = pipeline
run:  Products -> {
   group_by: productName, unitPrice    
   aggregate: all_avg_price  --measure: all(avg(unitPrice))
    
} -> {
    where: unitPrice > all_avg_price
    aggregate: result is count()
}


        
>>>markdown

As an excercise this can be also achieved by writing query and then running our source with this query joined in 'extend':
>>>malloy



query: temp_table is  Products -> {
    group_by: productID   
    aggregate: all_avg_price --measure: all(avg(unitPrice))
}

run: Products 
    extend {
        join_one: temp_table is from(->temp_table) on productID = temp_table.productID
        
    } -> {
    where: unitPrice > temp_table.all_avg_price
    aggregate: result is count()
    }
>>>markdown

Question 5: How many products cost between $15 and $25? (inclusive)
>>>malloy

run: Products -> {
    where: unitPrice >= 15 and unitPrice <= 25
    aggregate: product_count
}
>>>markdown

Question 6: What is the average number of products (not qty) per order? - this question was later clarified: we need to calculate average order size:

>>>markdown

Also calculated using pipeline:
>>>malloy

run: OrderDetails -> {
    group_by: orderID
    aggregate: product_count is count()
       
} -> {
    aggregate: result is avg(product_count)
}

>>>markdown

Question 7: What is the order value in $ of open orders? (not shipped)


For the first time we will make use o join to calculate the result. The join is specified in Orders source:

>>>malloy
run: Orders -> {
    
        where: shippedDate = null
        aggregate: orders_value is OrderDetails.revenue.sum() -- as dimension 'revenue' is foreign i need to put sum() at the end
        
}
>>>markdown
I cannot start from OrderDetails source as i can't add join to Orders inside. So i have two options:

1. create new source from OrderDetails and add join inside
2. local extension using 'run: source extend {}' in form of a pipeline


 I am using join_one as for each record in OrderDetails i have only one matching record in Orders source. Important thing is that i move back to my OrderDetails source and added dimension 'revenue' in extend clause. It is like a calculated column in Power Bi.
>>>malloy

--option 1 - extension in new source deifinition
source: OrdersDetailsExt is OrderDetails

    extend {
       
        join_one: Orders on Orders.orderID = orderID
    
        
        query: q7_result_2 is {
        where: Orders.shippedDate = null
        aggregate: test is sum(revenue) --as my 'revenue' dimension is local i can use sum(revenue)
        }
    }
>>>malloy
--option 2 - extension in 'run' clause - it can be used only in this query
run: OrderDetails
    extend {
         join_one: Orders on Orders.orderID = orderID
    } -> {
        where: Orders.shippedDate = null
        aggregate: test is sum(revenue) --as my 'revenue' dimension is local i can use sum(revenue)
    }
>>>markdown
Question 8: How many orders are single item (only one product ordered)?

To answer this question i need OrderDetails source. Something new here is the use of 'all' + grouping dimension. Thanks to that i can control on what granularity i am aggregating numbers:
>>>malloy
query: single_item_order is OrderDetails -> {
    group_by: orderID 
    aggregate: item_count is all(count(), orderID) --i am using grouping_dimension here
} -> {
    where: item_count = 1
    aggregate: result is count()
}
>>>markdown
Question 9: Avg sales per transaction for "Romero y Tobillo"

A nice question as this time i need 3 sources to answer. As i've already defined my model it should be easy - i will need Orders and OrderDetails but also Customers as name 'Romero y Tabillo' can be found only there:

>>>malloy
-- there is a typo in the question so to find correct companyName i've made a helper query:

run: Customers -> {
    project: companyName
    where: companyName ~ '%Romero%'
}
>>>malloy
-- joins works without any problems:

run: Orders -> {
    where: Customers.companyName = 'Romero y tomillo'
    group_by: orderID
    aggregate: revenue_per_order is OrderDetails.revenue.sum()
   
} -> {
    aggregate: result is avg(revenue_per_order)
}
>>>markdown
Question 10: How many days since 'North/South' last purchase?

I need to use Orders and Customers sources and also a built in time constant 'now' to get current date time. The result will be different depending on time when the query is evaluated.

To make everything work i am changing time stamps to dates using '::date'.
>>>malloy

run: Orders -> {
    where: Customers.companyName = 'North/South'
    group_by:
         order_date, --dimension added earlier to Orders source
         now_date is now::date  --timestamp to date 
    aggregate: max_order_date is all(max(order_date))::date
} 
-> {
    where: order_date = max_order_date
    group_by: result is days(order_date to now_date)
    
}

--this is output of first part of query:
run: Orders -> {
    where: Customers.companyName = 'North/South'
    group_by:
         order_date, --dimension added earlier to source
         now_date is now::date  --timestamp to date 
    aggregate: max_order_date is all(max(order_date))::date
}
>>>markdown
Question 11: How many customers have ordered only once?
>>>malloy
run: Orders -> {
    group_by: customerID
    aggregate: order_count --measure in Orders source
} -> {
    where: order_count = 1
    aggregate: result is count()
}
>>>markdown
Question 12: How many new customers in 1998? - (slightly modified, 1998 instead of 2022 as my version of data has different time range)

I've added new dimension to Orders source: order_year is year(orderDate).
Also i am using all with grouping dimension on this order_year dimension.
>>>malloy
run: Orders -> {
    group_by: orderID, customerID, order_year
    aggregate: all_min_order_year is all(min(order_year), customerID)
} -> {
    where: order_year = 1998 and all_min_order_year = 1998
    aggregate: result is count()
}
>>>markdown
Question 13: How many lost customers in 1998 (no purchases)? (slightly modified, 1998 instead of 2022 as my version of data has different time range, picked 1998)
>>>malloy
run: Orders -> {
    group_by: orderID, customerID, order_year
    aggregate: all_max_order_year is all(max(order_year), customerID)
} -> {
    where: all_max_order_year = 1997
    aggregate: result is count()
}
>>>markdown
Question 14: How many customers has never purchased Queso Cabrales?
>>>markdown
Pause - need to understand how joins work across
>>>malloy
-- works fine
run: Products -> {
    group_by: productName, Suppliers.companyName, Categories.categoryName
}
>>>malloy

-- works fine
run: OrderDetails -> {
    group_by: orderID, Products.productName
}
>>>malloy
-- doesn't work
run: OrderDetails -> {
    group_by: orderID, Products.productName, Suppliers.companyName, Categories.categoryName
}
>>>markdown
Question 15: How many customers have purchased only Queso Cabrales?
>>>markdown
Question 16: How many products are out of stock?
>>>markdown
Question 17: How many products need to be restocked (based on restock levels)?
>>>markdown
Question 18: How many products on order we need to restock?
>>>markdown
Question 19: What is the stocked value of the discontinued products?
>>>markdown
Question 20: Which vendor has the highest stock value?
>>>markdown
Question 21: How many employees (%) are female?
>>>markdown
Question 22: How many employees are 60 years old or over?
>>>markdown
Question 23: Which employee had the highest sales in 1997 - (slightly modified, 1997 instead of 2022 as my version of data has different time range)?
>>>markdown
Question 24: How many employees sold over 100K$ in 1997 (slightly modified, 1997 instead of 2022 as my version of data has different time range)?
>>>markdown
Question 25: How many employees got hired in 1994?